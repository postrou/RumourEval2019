{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('LINCLASS/')\n",
    "import download_emb as db\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = f.load_data('/data_ssd/vera/data/twitter-english/',\n",
    "                 '/data_ssd/vera/data/reddit-training-data/',\n",
    "                 '/data_ssd/vera/data/train-key.json')\n",
    "train['id'] = [i for i in range(len(train.index))]\n",
    "\n",
    "test = f.load_test_data('/data_ssd/vera/data/reddit-dev-data/',\n",
    "                      '/data_ssd/vera/data/dev-key.json')\n",
    "test['id'] = [i for i in range(len(test.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4878, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subtaskaenglish</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521352738891132929</th>\n",
       "      <td>What? \"@FootballcomEN: Unconfirmed reports cla...</td>\n",
       "      <td>comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521356252740608001</th>\n",
       "      <td>Umdlali webhola vele RT @FootballcomEN: Unconf...</td>\n",
       "      <td>comment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521366121484918785</th>\n",
       "      <td>@ohlozzie @FootballcomEN Who mentioned it bein...</td>\n",
       "      <td>deny</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521368940669583360</th>\n",
       "      <td>@AyyBant @FootballcomEN Fuck off. You're an at...</td>\n",
       "      <td>comment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "521352738891132929  What? \"@FootballcomEN: Unconfirmed reports cla...   \n",
       "521356252740608001  Umdlali webhola vele RT @FootballcomEN: Unconf...   \n",
       "521366121484918785  @ohlozzie @FootballcomEN Who mentioned it bein...   \n",
       "521368940669583360  @AyyBant @FootballcomEN Fuck off. You're an at...   \n",
       "\n",
       "                   subtaskaenglish  id  \n",
       "521352738891132929         comment   0  \n",
       "521356252740608001         comment   1  \n",
       "521366121484918785            deny   2  \n",
       "521368940669583360         comment   3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\t @JoeDavey7 @FootballcomEN fs Joe üòÇüòÇüòÇ\n",
      "After: \t fs joe \n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "ind = 17\n",
    "s = f.clean_str(train.loc[train.index[ind],'text'])\n",
    "print('Before:\\t', train.loc[train.index[ind],'text'])\n",
    "print('After: \\t', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = f.clean_text(train)\n",
    "test = f.clean_text(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create vocabulary tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000  #–ü–æ—Ä–æ–≥ —á–∞—Å—Ç–æ—Ç—ã\n",
    "voc = f.make_vocabulary(list(train.loc[:,'clean_text']), n)\n",
    "tf = f.tfidf(train, voc)\n",
    "tf_test = f.tfidf(test, voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–°–∫–∞—á–∏–≤–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã,–µ—Å–ª–∏ –Ω–µ —Å–∫–∞—á–∞–Ω—ã –µ—â–µ\n",
    "#db.download_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading....\n"
     ]
    }
   ],
   "source": [
    "#–ü–æ–¥–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "emb = db.load_emb('/data_ssd/vera/data/GoogleNews-vectors-negative300.bin.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "twit embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = f.emb_sent(train, tf, emb, dim = 300)\n",
    "test = f.emb_sent(test, tf_test, emb, dim = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train1.to_csv('/data_ssd/vera/data/train_1.csv', sep = ';') #save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tr  = pd.read_csv('/data_ssd/vera/data/train_1.csv', sep = ';')      #–µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = list(train.loc[:,'embed'])\n",
    "y = list(train.loc[:,'subtaskaenglish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#X, y = make_classification(n_samples=1000, n_features=4,\n",
    "#                            n_informative=2, n_redundant=0,\n",
    "#                            random_state=0, shuffle=False)\n",
    "\n",
    "clforest = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                             random_state=0)\n",
    "clforest.fit(X, y)\n",
    "\n",
    "#RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "#print(clf.feature_importances_)\n",
    "\n",
    "#print(clf.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = list(train.loc[:,'embed'])\n",
    "y_test = list(train.loc[:,'subtaskaenglish']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res_forest = clforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score SVC:\t 0.7166871668716687\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "acc_svc = sklearn.metrics.accuracy_score(y_test, y_res, normalize=True, sample_weight=None)\n",
    "acc_forest = sklearn.metrics.accuracy_score(y_test, y_res_forest, normalize=True, sample_weight=None)\n",
    "print('accuracy_score SVC:\\t', acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score SVC:\t 0.17917179171791717\n"
     ]
    }
   ],
   "source": [
    "ap_svc = sklearn.metrics.precision_score(y_test, y_res, average = 'macro')\n",
    "ap_forest = sklearn.metrics.precision_score(y_test, y_res_forest, average = 'macro')\n",
    "print('precision_score SVC:\\t', ap_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score SVC:\t 0.20874134224982085\n"
     ]
    }
   ],
   "source": [
    "apf_svc = sklearn.metrics.f1_score(y_test, y_res, average = 'macro')\n",
    "apf_forest = sklearn.metrics.f1_score(y_test, y_res_forest, average = 'macro')\n",
    "print('f1_score SVC:\\t', apf_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Rumour Stance classification\n",
      "Traceback (most recent call last):\n",
      "  File \"LSTM/outer_semeval2019.py\", line 67, in <module>\n",
      "    params, trials = parameter_search(ntrials, objective_function_stance_branchLSTM_RumEv, task)\n",
      "  File \"/home/verapolakova/project/RumourEval2019/baseline/LSTM/parameter_search.py\", line 28, in parameter_search\n",
      "    trials=trials)\n",
      "  File \"/data_ssd/vera/anaconda3/envs/python36_env/lib/python3.6/site-packages/hyperopt/fmin.py\", line 367, in fmin\n",
      "    return_argmin=return_argmin,\n",
      "  File \"/data_ssd/vera/anaconda3/envs/python36_env/lib/python3.6/site-packages/hyperopt/base.py\", line 635, in fmin\n",
      "    return_argmin=return_argmin)\n",
      "  File \"/data_ssd/vera/anaconda3/envs/python36_env/lib/python3.6/site-packages/hyperopt/fmin.py\", line 385, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"/data_ssd/vera/anaconda3/envs/python36_env/lib/python3.6/site-packages/hyperopt/fmin.py\", line 244, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "  File \"/data_ssd/vera/anaconda3/envs/python36_env/lib/python3.6/site-packages/hyperopt/fmin.py\", line 218, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"/data_ssd/vera/anaconda3/envs/python36_env/lib/python3.6/site-packages/hyperopt/fmin.py\", line 137, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"/data_ssd/vera/anaconda3/envs/python36_env/lib/python3.6/site-packages/hyperopt/base.py\", line 840, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"/home/verapolakova/project/RumourEval2019/baseline/LSTM/objective_functions.py\", line 16, in objective_function_stance_branchLSTM_RumEv\n",
      "    'train/train_array.npy'))\n",
      "  File \"/data_ssd/vera/anaconda3/envs/python36_env/lib/python3.6/site-packages/numpy/lib/npyio.py\", line 384, in load\n",
      "    fid = open(file, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'LSTM/preprocessing/saved_dataRumEval2019/train/train_array.npy'\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('LSTM/')\n",
    "!python LSTM/outer_semeval2019.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
